{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = '/models/image/inception/classify_image_graph_def.pb'\n",
    "DATA_PATH = '/data/video/video-level-features/'\n",
    "NPROD = 1\n",
    "LIMIT = 10\n",
    "\n",
    "import copy \n",
    "import logging\n",
    "import psycopg2\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter\n",
    "from heapq import merge\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from tensorflow.python.platform import gfile\n",
    "from t1000.embedding import video\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s  %(levelname)-8s %(message)s',\n",
    "                    datefmt='%m-%d %H:%M:%S')\n",
    "\n",
    "def fetch(dbname, user, host, password, query):\n",
    "    '''\n",
    "    Executes query on a given database\n",
    "    '''\n",
    "    connection_string = \"dbname='{0}' user='{1}' host='{2}' password='{3}'\".format(\n",
    "        dbname, user, host, password)\n",
    "    try:\n",
    "        conn = psycopg2.connect(connection_string)\n",
    "        curr = conn.cursor()\n",
    "        curr.execute(query)\n",
    "        res = curr.fetchall()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        logging.exception('')\n",
    "    finally:\n",
    "        curr.close()\n",
    "        conn.close()\n",
    "        \n",
    "    return res\n",
    "\n",
    "def inner_join(a, b):\n",
    "    '''\n",
    "    Joins two iterables of tuples on the first \n",
    "    element\n",
    "    \n",
    "    Arguments:\n",
    "    a - list of tuples (id, x)\n",
    "    b - list of tuples (id, y)\n",
    "    \n",
    "    Returns:\n",
    "    list of tuples (id, x, y)\n",
    "    '''\n",
    "    key = itemgetter(0)\n",
    "    a.sort(key=key) \n",
    "    b.sort(key=key)\n",
    "    for _, group in groupby(merge(a, b, key=key), key):\n",
    "        row_a, row_b = next(group), next(group, None)\n",
    "        if row_b is not None: # join\n",
    "            yield row_a + row_b[1:]\n",
    "            \n",
    "\n",
    "def filter_videos(videos, min_count = 10):\n",
    "    '''\n",
    "    Filters videos and returns mapping to the original tags\n",
    "    \n",
    "    Returns:\n",
    "    filtered       - a list with transformed and filtered videos\n",
    "    tags_2_indices - a dictinary that transforms tags to rank of their\n",
    "                     frequencies\n",
    "    indices_2_tags - inverse dictionary\n",
    "    '''\n",
    "    \n",
    "    # we have to iterate twice, first to create dictionary, then \n",
    "    # then to filter tags and transform the list\n",
    "    if not isinstance(videos, list):\n",
    "        videos = list(videos)\n",
    "        \n",
    "    # Filters top tags and creates mapping\n",
    "    count = Counter(itertools.chain(*[tup[1] for tup in videos]))\n",
    "    tags_2_indices = { \n",
    "        tag_id: index \n",
    "            for index, (tag_id, count) in enumerate(count.most_common(), 1)\n",
    "            if count >= min_count \n",
    "    }\n",
    "\n",
    "    # reverse index for decoding \n",
    "    indices_2_tags = { \n",
    "        v: k for k, v in tags_2_indices.items()\n",
    "    }\n",
    "\n",
    "    filtered = []\n",
    "    for video_id, tags, url in videos:\n",
    "        encoded = [tags_2_indices[t] for t in tags if t in tags_2_indices]\n",
    "        if encoded:\n",
    "            filtered.append((video_id, encoded, url))\n",
    "                \n",
    "    return filtered, tags_2_indices, indices_2_tags\n",
    "\n",
    "\n",
    "## Sequential dataprocessing\n",
    "class FramesIterator:\n",
    "    '''iterator that yields raw frames from database'''\n",
    "\n",
    "    def __init__(self, videos):\n",
    "        self.videos = copy.deepcopy(videos)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.videos:\n",
    "            logging.debug(\"Downloading url\")\n",
    "            video_id, video_tags, video_path = self.videos.pop()\n",
    "            \n",
    "            # this could be done in parallel\n",
    "            frames = video.extract_frames(video_path)\n",
    "        else:\n",
    "            raise StopIteration\n",
    "        \n",
    "        return video_id, frames, video_tags\n",
    "\n",
    "\n",
    "def extract_incepction_v3(frame_iterator, model_dir, data_dir, logging_step = 100):\n",
    "    '''\n",
    "    Extract incepction_v3 features from frame generator.\n",
    "    \n",
    "    Inputs:\n",
    "    frame_iterator - an iterator yielding video frames\n",
    "    model_dir      - a directory to inception model \n",
    "    logging_step   - log progress after this number of steps\n",
    "    '''\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info(\"Extracting inception features\")\n",
    "\n",
    "    # load incepction 3 graph\n",
    "    with gfile.FastGFile(model_dir, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # TODO: add queuing and batching for optimal performance\n",
    "        for index, item in enumerate(frame_iterator):\n",
    "            item_id, frames, tags = item\n",
    "            \n",
    "            if index % logging_step == 0:\n",
    "                logger.info(\"Extracting features from video %s [%d]\" % (item_id, index))\n",
    "            \n",
    "            \n",
    "            img_features = []\n",
    "            for frame in frames:\n",
    "                # get tensor from network\n",
    "                pool3_layer = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "                predictions = sess.run(pool3_layer, {'DecodeJpeg:0': frame})\n",
    "\n",
    "                # concatenate features\n",
    "                features = np.squeeze(predictions)\n",
    "                img_features.append(features)\n",
    "\n",
    "            file_name = os.path.join(data_dir, '{0}.pickle'.format(item_id))\n",
    "            fv3_features = np.array(img_features, dtype=np.float32)\n",
    "            \n",
    "            with open(file_name, 'wb') as handle:\n",
    "                pickle.dump((fv3_features, tags), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "            if index % logging_step == 0:\n",
    "                logger.info(\"Extracting features from video %s [%d] [DONE!]\" % (item_id, index))\n",
    "\n",
    "def fetch_sq(work, model_path = MODEL_PATH, data_path = DATA_PATH):\n",
    "    frames = FramesIterator(work)\n",
    "    extract_incepction_v3(frames, model_path, data_path, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producer-Consumer Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def chunks(seq, num):\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "\n",
    "    return out\n",
    "\n",
    "class Producer(multiprocessing.Process):\n",
    "    def __init__(self, items, idx, queue):\n",
    "        super(Producer, self).__init__()\n",
    "        self.items = items\n",
    "        self.queue = queue\n",
    "        self.idx = idx\n",
    "\n",
    "    def run(self):\n",
    "        logger = logging.getLogger(__name__)\n",
    "        logger.info(\"Starting %d producer \" % (self.idx ))\n",
    "        \n",
    "        while self.items:\n",
    "            # get items\n",
    "            video_id, video_tags, video_path = self.items.pop()\n",
    "\n",
    "            # extract frames\n",
    "            logger.debug(\"[Producer] Downloading url\")\n",
    "            frames = video.extract_frames(video_path)\n",
    "            logger.debug(\"[Producer] Extracted frames from %s\" % video_id)\n",
    "\n",
    "            # add items to queue\n",
    "            self.queue.put((video_id, frames, video_tags))\n",
    "\n",
    "        logger.info(\"[Producer] This is it! [%d]\" % self.idx)\n",
    "        self.queue.put(None)\n",
    "        \n",
    "        logger.info('[Producer] Ending producer')\n",
    "        return\n",
    "\n",
    "class Consumer(multiprocessing.Process):\n",
    "    def __init__(self, idx, queues, model_dir, data_dir, logging_step = 100):\n",
    "        super(Consumer, self).__init__()\n",
    "        self.queues = queues\n",
    "        self.idx = idx\n",
    "        self.model_dir = model_dir\n",
    "        self.data_dir = data_dir\n",
    "        self.logging_step = logging_step\n",
    "\n",
    "    def run(self):\n",
    "        logger = logging.getLogger(__name__)\n",
    "        logger.info(\"Starting %d consumer\" % (self.idx ))\n",
    "        \n",
    "            # load incepction 3 graph\n",
    "        with gfile.FastGFile(self.model_dir, 'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            _ = tf.import_graph_def(graph_def, name='')\n",
    "            \n",
    "        logger.info(\"Loaded graph\")\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            # TODO: add queuing and batching for optimal performance\n",
    "            processed_items = 0\n",
    "            while self.queues:\n",
    "                for queue in self.queues:\n",
    "                    item = queue.get()\n",
    "                    if item is None:\n",
    "                        self.queues[:] = [q for q in self.queues if q != queue]\n",
    "                        logger.debug(\n",
    "                            \"[Consumer] Rmoved %s from queues. %d left\" % (queue, len(self.queues))\n",
    "                        )\n",
    "                        continue\n",
    "                    \n",
    "\n",
    "                    item_id, frames, tags = item\n",
    "                    if processed_items % self.logging_step == 0:\n",
    "                        logger.info(\n",
    "                            \"[Consumer] Extracting features from video %s [%d]\" % (item_id, processed_items)\n",
    "                        )\n",
    "                        \n",
    "                    img_features = []\n",
    "                    for index, frame in enumerate(frames):\n",
    "                        # get tensor from network\n",
    "                        pool3_layer = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "                        predictions = sess.run(pool3_layer, {'DecodeJpeg:0': frame})\n",
    "\n",
    "                        # concatenate features\n",
    "                        features = np.squeeze(predictions)\n",
    "                        img_features.append(features)\n",
    "\n",
    "                        \n",
    "                    file_name = os.path.join(self.data_dir, '{0}.pickle'.format(item_id))\n",
    "                    fv3_features = np.array(img_features, dtype=np.float32)\n",
    "                    \n",
    "                    with open(file_name, 'wb') as handle:\n",
    "                        pickle.dump((fv3_features, tags), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                    \n",
    "                    if processed_items % self.logging_step == 0:\n",
    "                        logger.info(\n",
    "                            \"[Consumer] Extracting features from video %s [DONE!][%d]\" % (item_id, processed_items))\n",
    "\n",
    "                    # Increment counter\n",
    "                    processed_items = processed_items + 1\n",
    "                    \n",
    "                   \n",
    "        logger.info(\"Ending %d consumer\" % (self.idx ))\n",
    "        return\n",
    "\n",
    "def fetch_mp(work, nprod = NPROD, model_path = MODEL_PATH, data_path = DATA_PATH):\n",
    "    work = chunks(work, nprod)\n",
    "    #make reader for reading data. lets call this object Producer\n",
    "    producers = []\n",
    "    queues = []\n",
    "    for idx in range(nprod):   \n",
    "        queues.append(multiprocessing.Queue())\n",
    "        producers.append(Producer(work[idx], idx, queues[idx]))\n",
    "\n",
    "    #make receivers for the data. Lets call these Consumers\n",
    "    #Each consumer is assigned a queue\n",
    "    consumer_object = Consumer(1, queues, model_path, data_path)\n",
    "    consumer_object.start()\n",
    "\n",
    "    # start the producer processes\n",
    "    for producer_object in producers:\n",
    "        producer_object.start()\n",
    "\n",
    "\n",
    "    #Join all started processes\n",
    "    consumer_object.join()    \n",
    "\n",
    "    for producer_object in producers:\n",
    "        producer_object.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "## Videos data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbname='ds-wizards'\n",
    "user='wizard'\n",
    "host='192.95.32.117'\n",
    "password='GaG23jVxZhMnQaU53r8o'\n",
    "\n",
    "VQUERY = \"select post_id, url from videos where status='ok'\"\n",
    "\n",
    "vres = fetch(dbname, user, host, password, VQUERY)\n",
    "vres = [(post_id.split(\"_\")[1], url) for post_id, url in vres]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbname='ds-content-tags'\n",
    "user='ds-content-tags'\n",
    "password='0fXjWl592vNf1gYvIw8w'\n",
    "host='192.95.32.117'\n",
    "\n",
    "TQUERY = \"select id, tags from videos where tags is not NULL\"\n",
    "TAGS = \"select tag_id, name, path from content_tags\"\n",
    "\n",
    "tres = fetch(dbname, user, host, password, TQUERY)\n",
    "\n",
    "tags = { \n",
    "    tag_id: (name, path) for (tag_id, name, path) in fetch(\n",
    "        dbname, user, host, password, TAGS) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join videos with tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = inner_join(tres, vres)\n",
    "filtered, t2i, i2t = filter_videos(videos, 10)\n",
    "print(\"Found %d videos with %d unique tags\" % (len(filtered), len(t2i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "work = filtered[:LIMIT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def run_and_measure(fun):\n",
    "    start_time = time.time()\n",
    "    fun()\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    print(\"Elapsed time was %g seconds [%g]\" % (elapsed, elapsed/len(work)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsq = lambda : fetch_sq(work, model_path=MODEL_PATH, data_path=os.path.join(DATA_PATH, 'seq'))\n",
    "fmp = lambda : fetch_mp(work, nprod=4, model_path=MODEL_PATH, data_path=os.path.join(DATA_PATH, 'mp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_and_measure(fmp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
